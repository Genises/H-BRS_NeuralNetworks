{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework-  26.11.2018:\n",
    "## State of the Art Neural Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this homework is to implement and evaluate the sota architectures presented in the lecture.\n",
    "However, you are encouraged to try your own layer module ideas.\n",
    "Feel free to consult the [Keras source code](https://github.com/keras-team/keras-applications):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Based on the CNN modules presented in the lecture e.g. VGG16, Inception, ResNet, Xception, DenseNet, come up with your own CNN module and write a small text discussing your idea and motivations behind the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate all your module using the Keras CIFAR10 dataset splits (The model with best test accuracy will present their solution to the class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))\n",
    "#print(x_train[0,:,:,:])#,RGB = 3\n",
    "#print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data to fit softmax\n",
    "from tensorflow.keras import utils\n",
    "y_train_categorical = utils.to_categorical(y_train, 10)\n",
    "y_test_categorical = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "img_shape = (32,32,3)\n",
    "classes_number = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 24,806,194\n",
      "Trainable params: 24,787,038\n",
      "Non-trainable params: 19,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MODEL: AlexNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "alexnet = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "# 96 filter mit 11x11 convolution too big for 32x32 img?\n",
    "alexnet.add(Conv2D(96, (11, 11), input_shape=img_shape, padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4\n",
    "alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "\n",
    "# Layer 5\n",
    "alexnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "alexnet.add(Flatten())\n",
    "\n",
    "# Layer 6 - fully connected layer\n",
    "alexnet.add(Dense(4096))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "alexnet.add(Dense(4096))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 8\n",
    "alexnet.add(Dense(classes_number))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('softmax'))\n",
    "\n",
    "alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 1188s 24ms/step - loss: 1.5467 - acc: 0.4583 - val_loss: 2.8624 - val_acc: 0.2014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf45b67f60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile \n",
    "alexnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train\n",
    "alexnet.fit(x_train, y_train_categorical, validation_data=(x_test,y_test_categorical), batch_size=1000, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/1\n",
    "50000/50000 [==============================] - 1188s 24ms/step - loss: 1.5467 - acc: 0.4583 - val_loss: 2.8624 - val_acc: 0.2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate your module using the FERPlus dataset (The model with the best test accuracy will present their solution to the class).\n",
    "\n",
    "    3.1 Download the [FER2013 dataset](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) (images_path).\n",
    "    \n",
    "    3.2 Download the [FERPlus labels](https://github.com/Microsoft/FERPlus/blob/master/fer2013new.csv) (labels_path).\n",
    "    \n",
    "    3.3 Use the following code snippet to load the dataset giving the appropiate paths to the csv files downloaded in 3.1 and 3.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERPlus(object):\n",
    "    \"\"\"Class for loading FER2013 [1] emotion classification dataset with\n",
    "    the FERPlus labels [2]:\n",
    "    [1] kaggle.com/c/challenges-in-representation-learning-facial-\\\n",
    "            expression-recognition-challenge\n",
    "    [2] github.com/Microsoft/FERPlu://github.com/Microsoft/FERPlus\"\"\"\n",
    "\n",
    "    def __init__(self, images_path, labels_path, split='train', image_size=(48, 48),\n",
    "                 dataset_name='FERPlus'):\n",
    "\n",
    "        self.split = split\n",
    "        self.image_size = image_size\n",
    "        self.dataset_name = dataset_name\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.class_names = ['neutral', 'happiness', 'surprise', 'sadness',\n",
    "                            'anger', 'disgust', 'fear', 'contempt']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.arg_to_name = dict(zip(range(self.num_classes), self.class_names))\n",
    "        self.name_to_arg = dict(zip(self.class_names, range(self.num_classes)))\n",
    "        self._split_to_filter = {\n",
    "            'train': 'Training', 'val': 'PublicTest', 'test': 'PrivateTest'}\n",
    "\n",
    "    def load_data(self):\n",
    "        filter_name = self._split_to_filter[self.split]\n",
    "        pixel_sequences = pd.read_csv(self.images_path)\n",
    "        pixel_sequences = pixel_sequences[pixel_sequences.Usage == filter_name]\n",
    "        pixel_sequences = pixel_sequences['pixels'].tolist()\n",
    "        faces = []\n",
    "        for pixel_sequence in pixel_sequences:\n",
    "            face = [float(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(48, 48)\n",
    "            faces.append(cv2.resize(face, self.image_size))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "\n",
    "        emotions = pd.read_csv(self.labels_path)\n",
    "        emotions = emotions[emotions.Usage == filter_name]\n",
    "        emotions = emotions.iloc[:, 2:10].values\n",
    "        N = np.sum(emotions, axis=1)\n",
    "        mask = N != 0\n",
    "        N, faces, emotions = N[mask], faces[mask], emotions[mask]\n",
    "        emotions = emotions / np.expand_dims(N, 1)\n",
    "        return faces, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_5_input to have shape (32, 32, 3) but got array with shape (48, 48, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-891ba35fdcbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mownnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m   1752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[1;32m--> 992\u001b[1;33m                                                      class_weight, batch_size)\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         exception_prefix='input')\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    333\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_5_input to have shape (32, 32, 3) but got array with shape (48, 48, 1)"
     ]
    }
   ],
   "source": [
    "validation_data = FERPlus(\"fer2013\\\\fer2013.csv\", \"fer2013new.csv\")\n",
    "faces, emotions = validation_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 30)        5790      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 60)        115260    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 60)        240       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 60)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 60)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         123008    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 64)          65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,505,844\n",
      "Trainable params: 1,501,164\n",
      "Non-trainable params: 4,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MODEL: AlexNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "# About CIFAR10:\n",
    "# The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \n",
    "# with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "#Hyperparameters\n",
    "img_shape = (32,32,3)\n",
    "classes_number = 10\n",
    "\n",
    "ownnet = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "# 16 pixels to one: 32 -> 8\n",
    "# How many input neurons -> Lecture showed that less parameters and more layers are more useful\n",
    "ownnet.add(Conv2D(classes_number * 3, (8, 8), input_shape=img_shape, padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Another layer with double amount of filters\n",
    "ownnet.add(Conv2D(classes_number * 6, (8, 8), input_shape=img_shape, padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "ownnet.add(Conv2D(128, (4, 4), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "ownnet.add(Conv2D(128, (3, 3), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4\n",
    "ownnet.add(Conv2D(128, (3, 3), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "\n",
    "# Layer 5\n",
    "ownnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Another layer\n",
    "ownnet.add(Conv2D(64, (2, 2), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "\n",
    "ownnet.add(Flatten())\n",
    "\n",
    "# Layer 6 - fully connected layer\n",
    "ownnet.add(Dense(1024))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "ownnet.add(Dense(512))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('relu'))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 8\n",
    "ownnet.add(Dense(classes_number))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('softmax'))\n",
    "\n",
    "ownnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/1\n",
    "50000/50000 [==============================] - 287s 6ms/step - loss: 1.7042 - acc: 0.3946 - val_loss: 2.1963 - val_acc: 0.1489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 1.7042 - acc: 0.3946 - val_loss: 2.1963 - val_acc: 0.1489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf372bd898>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile \n",
    "ownnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train\n",
    "ownnet.fit(x_train, y_train_categorical, validation_data=(x_test,y_test_categorical), batch_size=1000, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_224 (Conv2D)          (None, 12, 12, 100)       30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_301 (Bat (None, 12, 12, 100)       400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_231 (LeakyReLU)  (None, 12, 12, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_225 (Conv2D)          (None, 12, 12, 80)        512080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_302 (Bat (None, 12, 12, 80)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_232 (LeakyReLU)  (None, 12, 12, 80)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_163 (MaxPoolin (None, 6, 6, 80)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_226 (Conv2D)          (None, 6, 6, 256)         737536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_303 (Bat (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_233 (LeakyReLU)  (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_164 (MaxPoolin (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_227 (Conv2D)          (None, 3, 3, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_304 (Bat (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_234 (LeakyReLU)  (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_228 (Conv2D)          (None, 1, 1, 128)         262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_305 (Bat (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_235 (LeakyReLU)  (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_229 (Conv2D)          (None, 1, 1, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_306 (Bat (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_236 (LeakyReLU)  (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_230 (Conv2D)          (None, 1, 1, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_307 (Bat (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_237 (LeakyReLU)  (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_308 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_238 (LeakyReLU)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_309 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_239 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_310 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_240 (LeakyReLU)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "batch_normalization_311 (Bat (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,657,254\n",
      "Trainable params: 2,653,802\n",
      "Non-trainable params: 3,452\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Results of frist try were mixed, therefore some adjustments\n",
    "# Use Leaky RelU instead of normal ReLU to prevent dead ReLU\n",
    "# Add more filters to first layer, less to 2nd\n",
    "# Added another dense layer\n",
    "# Less pooling functions\n",
    "\n",
    "#MODEL: AlexNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "\n",
    "# About CIFAR10:\n",
    "# The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \n",
    "# with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "#Hyperparameters\n",
    "img_shape = (32,32,3)\n",
    "classes_number = 10\n",
    "\n",
    "ownnet = Sequential()\n",
    "\n",
    "# Use smaller kernel but combinded with strides\n",
    "ownnet.add(Conv2D(classes_number * 10, (10, 10), input_shape=img_shape, padding='valid', strides=2))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Another layer with double amount of filters\n",
    "ownnet.add(Conv2D(classes_number * 8, (8, 8), input_shape=img_shape, padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "ownnet.add(Conv2D(256, (6, 6), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "ownnet.add(Conv2D(128, (5, 5), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4\n",
    "ownnet.add(Conv2D(128, (4, 4), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Layer 5\n",
    "ownnet.add(Conv2D(64, (3, 3), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Another layer\n",
    "ownnet.add(Conv2D(64, (2, 2), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Flatten())\n",
    "\n",
    "# Layer 6 - fully connected layer\n",
    "ownnet.add(Dense(512))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "ownnet.add(Dense(256))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "ownnet.add(Dense(128))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 8\n",
    "ownnet.add(Dense(classes_number))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('softmax'))\n",
    "\n",
    "ownnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " 5000/50000 [==>...........................] - ETA: 7:47 - loss: 2.6747 - acc: 0.1000"
     ]
    }
   ],
   "source": [
    "#Compile \n",
    "ownnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train\n",
    "ownnet.fit(x_train, y_train_categorical, validation_data=(x_test,y_test_categorical), batch_size=1000, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/1\n",
    "50000/50000 [==============================] - 461s 9ms/step - loss: 2.1342 - acc: 0.2192 - val_loss: 2.3551 - val_acc: 0.1136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 100)       2800      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 100)       400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 80)        200080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 80)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 80)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       368768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 96)          307296    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 58)          33466     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 58)          232       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4, 58)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 42)          9786      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 42)          168       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 42)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               172288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,240,646\n",
      "Trainable params: 1,238,530\n",
      "Non-trainable params: 2,116\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2nd try results were worse: Changeing first layer: No strides and smaller kernles (to enable edge detection)\n",
    "# Using elu function instead of relu at two random points\n",
    "# Reduced amount of parameters extremly (especially less filters in first few layers)\n",
    "# Added another filter layer at start and another dense layer at end, therefore reduced density.\n",
    "\n",
    "#MODEL: AlexNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "\n",
    "# About CIFAR10:\n",
    "# The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \n",
    "# with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "#Hyperparameters\n",
    "img_shape = (32,32,3)\n",
    "classes_number = 10\n",
    "\n",
    "ownnet = Sequential()\n",
    "\n",
    "# Use smaller kernel to improve potential edge detection \n",
    "ownnet.add(Conv2D(classes_number * 10, (3, 3), input_shape=img_shape, padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Another layer with double amount of filters\n",
    "ownnet.add(Conv2D(classes_number * 8, (5, 5), input_shape=img_shape, padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "ownnet.add(Conv2D(128, (6, 6), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('elu'))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "ownnet.add(Conv2D(96, (5, 5), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4\n",
    "ownnet.add(Conv2D(64, (4, 4), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Layer 5\n",
    "ownnet.add(Conv2D(58, (3, 3), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('elu'))\n",
    "\n",
    "# Another layer\n",
    "ownnet.add(Conv2D(42, (2, 2), padding='same'))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Flatten())\n",
    "\n",
    "# Layer 6 - fully connected layer\n",
    "ownnet.add(Dense(256))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "ownnet.add(Dense(128))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('elu'))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "ownnet.add(Dense(64))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "ownnet.add(Dense(32))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(LeakyReLU(alpha=0.01))\n",
    "ownnet.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Layer 8\n",
    "ownnet.add(Dense(classes_number))\n",
    "ownnet.add(BatchNormalization())\n",
    "ownnet.add(Activation('softmax'))\n",
    "\n",
    "ownnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 26171s 523ms/step - loss: 2.2899 - acc: 0.1791 - val_loss: 12.4215 - val_acc: 0.1001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15dca319ba8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile \n",
    "ownnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train\n",
    "ownnet.fit(x_train, y_train_categorical, validation_data=(x_test,y_test_categorical), batch_size=1000, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/1\n",
    "50000/50000 [==============================] - 26171s 523ms/step - loss: 2.2899 - acc: 0.1791 - val_loss: 12.4215 - val_acc: 0.1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_5_input to have shape (32, 32, 3) but got array with shape (48, 48, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2d51adcf99d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mownnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m   1752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[1;32m--> 992\u001b[1;33m                                                      class_weight, batch_size)\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         exception_prefix='input')\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Studium\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    333\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_5_input to have shape (32, 32, 3) but got array with shape (48, 48, 1)"
     ]
    }
   ],
   "source": [
    "loss = ownnet.evaluate(faces, emotions)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift + Tab --> Documentation\n",
    "Tab --> Code completition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
